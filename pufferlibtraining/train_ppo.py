#!/usr/bin/env python3
"""
Multi-stage RL training pipeline for stock trading using Amazon Toto forecasts.

The pipeline consists of three stages:
    1. Generic forecaster training on all available stocks.
    2. Specialist fine-tuning per target stock.
    3. Differentiable portfolio allocation RL over stock pairs.

This script orchestrates the stages using the hftraining modules so that the
resulting models can be consumed by the vectorised PufferLib environments.
"""

from __future__ import annotations

import argparse
import json
import logging
from pathlib import Path
from typing import Dict, Iterable, List, Sequence, Tuple

from hftraining.base_model_trainer import BaseModelTrainer, PortfolioRLConfig
from hftraining.toto_features import TotoOptions


LOGGER = logging.getLogger("pufferlibtraining.pipeline")


def _parse_symbol_list(raw: str, field: str) -> List[str]:
    tokens = [tok.strip().upper() for tok in raw.split(",") if tok.strip()]
    if not tokens:
        raise argparse.ArgumentTypeError(f"{field} must contain at least one symbol")
    return tokens


def _parse_pairs(pair_args: Sequence[str], fallback: Sequence[str]) -> List[Tuple[str, str]]:
    pairs: List[Tuple[str, str]] = []
    for raw in pair_args:
        cleaned = raw.replace("/", ",")
        bits = [b.strip().upper() for b in cleaned.split(",") if b.strip()]
        if len(bits) != 2:
            raise argparse.ArgumentTypeError(
                f"Unable to parse pair '{raw}'. Use SYMBOL_A,SYMBOL_B or SYMBOL_A/SYMBOL_B."
            )
        pairs.append((bits[0], bits[1]))

    if not pairs:
        fallback = [sym.upper() for sym in fallback]
        pairs = [
            (fallback[i], fallback[i + 1])
            for i in range(len(fallback) - 1)
        ]
    return pairs


def _ensure_data(symbols: Iterable[str], data_root: Path) -> None:
    missing: List[str] = []
    for sym in symbols:
        matches = list(data_root.rglob(f"*{sym.upper()}*.csv"))
        if not matches:
            missing.append(sym.upper())
    if missing:
        raise FileNotFoundError(
            f"No CSV data found under '{data_root}' for symbols: {', '.join(sorted(set(missing)))}"
        )


def _setup_logging(verbose: bool) -> None:
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
    )


def build_argument_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="Run the full multi-stage Toto-enhanced RL training pipeline."
    )

    parser.add_argument(
        "--base-stocks",
        type=str,
        default="AAPL,AMZN,MSFT,NVDA,GOOGL",
        help="Comma-separated list of symbols used for the generic forecaster.",
    )
    parser.add_argument(
        "--specialist-stocks",
        type=str,
        default="AAPL,AMZN,MSFT",
        help="Comma-separated list of symbols that receive specialist fine-tuning.",
    )
    parser.add_argument(
        "--pair",
        action="append",
        default=[],
        help="Specify a stock pair (SYMBOL_A,SYMBOL_B). Repeat for multiple pairs. "
             "Defaults to adjacent pairs from --specialist-stocks.",
    )

    parser.add_argument(
        "--trainingdata-dir",
        type=str,
        default="trainingdata",
        help="Directory containing raw CSVs for Toto feature generation.",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="pufferlibtraining/models",
        help="Directory where checkpoints will be written.",
    )
    parser.add_argument(
        "--tensorboard-dir",
        type=str,
        default="pufferlibtraining/logs",
        help="Directory where TensorBoard logs will be stored.",
    )

    parser.add_argument(
        "--skip-base",
        action="store_true",
        help="Skip generic forecaster training (requires --base-checkpoint).",
    )
    parser.add_argument(
        "--base-checkpoint",
        type=str,
        default="",
        help="Path to an existing base checkpoint when skipping stage 1.",
    )
    parser.add_argument(
        "--base-steps",
        type=int,
        default=20000,
        help="Maximum optimisation steps for the base model.",
    )
    parser.add_argument(
        "--base-batch-size",
        type=int,
        default=48,
        help="Batch size for the base model trainer.",
    )
    parser.add_argument(
        "--base-learning-rate",
        type=float,
        default=1e-4,
        help="Learning rate for the generic forecaster.",
    )
    parser.add_argument(
        "--progressive-base-steps",
        type=str,
        default="",
        help="Comma-separated schedule of additional base-training step increments (enables staged training).",
    )

    parser.add_argument(
        "--skip-specialists",
        action="store_true",
        help="Skip per-stock specialist fine-tuning.",
    )
    parser.add_argument(
        "--finetune-epochs",
        type=int,
        default=8,
        help="Number of epochs for each specialist fine-tuning run.",
    )
    parser.add_argument(
        "--finetune-learning-rate",
        type=float,
        default=5e-5,
        help="Learning rate used for specialist fine-tuning.",
    )

    parser.add_argument(
        "--skip-rl",
        action="store_true",
        help="Skip differentiable portfolio RL training.",
    )
    parser.add_argument(
        "--rl-epochs",
        type=int,
        default=20,
        help="Epochs for portfolio RL optimisation.",
    )
    parser.add_argument(
        "--rl-hidden-size",
        type=int,
        default=256,
        help="Hidden dimension for the allocation transformer.",
    )
    parser.add_argument(
        "--rl-num-layers",
        type=int,
        default=4,
        help="Number of transformer encoder layers in the allocation model.",
    )
    parser.add_argument(
        "--rl-num-heads",
        type=int,
        default=4,
        help="Number of attention heads for the allocation model.",
    )
    parser.add_argument(
        "--rl-learning-rate",
        type=float,
        default=3e-4,
        help="Learning rate for the differentiable portfolio trainer.",
    )
    parser.add_argument(
        "--rl-batch-size",
        type=int,
        default=128,
        help="Batch size for portfolio RL.",
    )
    parser.add_argument(
        "--transaction-cost-bps",
        type=float,
        default=10.0,
        help="Transaction cost used in differentiable profit calculations (basis points).",
    )
    parser.add_argument(
        "--risk-penalty",
        type=float,
        default=0.1,
        help="Sharpe-based risk penalty coefficient.",
    )
    parser.add_argument(
        "--leverage-limit",
        type=float,
        default=2.0,
        help="Maximum gross exposure for the RL allocation head.",
    )
    parser.add_argument(
        "--borrowing-cost",
        type=float,
        default=0.0675,
        help="Annualised borrowing cost applied to leverage above 1Ã—.",
    )
    parser.add_argument(
        "--trading-days-per-year",
        type=int,
        default=252,
        help="Trading days per year used to annualise borrowing cost.",
    )

    parser.add_argument(
        "--device",
        type=str,
        default="cuda" if TotoOptions().toto_device == "cuda" else "cpu",
        help="Torch device string for Toto forecasts and RL training.",
    )
    parser.add_argument(
        "--sequence-length",
        type=int,
        default=60,
        help="Context window length used for Toto conditioning.",
    )
    parser.add_argument(
        "--toto-horizon",
        type=int,
        default=8,
        help="Prediction horizon (in steps) for Toto forecasts.",
    )
    parser.add_argument(
        "--toto-num-samples",
        type=int,
        default=256,
        help="Number of forecast samples when using the Toto backend.",
    )
    parser.add_argument(
        "--toto-model-id",
        type=str,
        default="Datadog/Toto-Open-Base-1.0",
        help="Model identifier for Toto feature generation.",
    )
    parser.add_argument(
        "--toto-targets",
        type=str,
        default="close,open,high,low",
        help="Comma-separated list of price lines to feed into Toto forecasts (e.g., close,high,low).",
    )
    parser.add_argument(
        "--disable-toto",
        action="store_true",
        help="Disable Toto feature generation (falls back to statistical forecasts).",
    )

    parser.add_argument(
        "--summary-path",
        type=str,
        default="pufferlibtraining/models/pipeline_summary.json",
        help="Location to write the training summary JSON.",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable debug-level logging.",
    )

    return parser


def run_pipeline(args: argparse.Namespace) -> Dict[str, object]:
    data_root = Path(args.trainingdata_dir).expanduser().resolve()
    if not data_root.exists():
        fallback = Path("tototraining") / "trainingdata" / "train"
        if fallback.exists():
            LOGGER.warning(
                "Training data directory '%s' not found. Falling back to '%s'.",
                data_root,
                fallback.resolve(),
            )
            data_root = fallback.resolve()
        else:
            raise FileNotFoundError(f"Training data directory '{data_root}' does not exist")

    base_symbols = _parse_symbol_list(args.base_stocks, "base-stocks")
    specialist_symbols = _parse_symbol_list(args.specialist_stocks, "specialist-stocks")
    all_symbols = sorted(set(base_symbols) | set(specialist_symbols))
    pairs = _parse_pairs(args.pair, specialist_symbols)

    _ensure_data(all_symbols, data_root)

    output_dir = Path(args.output_dir).expanduser().resolve()
    tensorboard_dir = Path(args.tensorboard_dir).expanduser().resolve()
    output_dir.mkdir(parents=True, exist_ok=True)
    tensorboard_dir.mkdir(parents=True, exist_ok=True)

    toto_targets = [t.strip() for t in args.toto_targets.split(",") if t.strip()]
    toto_opts = TotoOptions(
        use_toto=not args.disable_toto,
        horizon=args.toto_horizon,
        context_length=args.sequence_length,
        num_samples=args.toto_num_samples,
        toto_model_id=args.toto_model_id,
        toto_device=args.device,
        target_columns=toto_targets or ("close",),
    )

    LOGGER.info("Initialising BaseModelTrainer with Toto options: %s", toto_opts)
    trainer = BaseModelTrainer(
        base_stocks=base_symbols,
        output_dir=str(output_dir),
        tensorboard_dir=str(tensorboard_dir),
        use_toto_forecasts=not args.disable_toto,
        toto_options=toto_opts,
        data_dir=str(data_root),
    )

    progressive_schedule: Optional[List[int]] = None

    summary: Dict[str, object] = {
        "base_checkpoint": None,
        "specialists": {},
        "portfolio_pairs": {},
        "config": {
            "base_symbols": base_symbols,
            "specialist_symbols": specialist_symbols,
            "pairs": [list(pair) for pair in pairs],
            "trainingdata_dir": str(data_root),
            "output_dir": str(output_dir),
            "tensorboard_dir": str(tensorboard_dir),
            "toto": {
                "enabled": not args.disable_toto,
                "horizon": args.toto_horizon,
                "context_length": args.sequence_length,
                "num_samples": args.toto_num_samples,
                "model_id": args.toto_model_id,
                "targets": toto_targets or ("close",),
            },
            "rl": {
                "transaction_cost_bps": args.transaction_cost_bps,
                "risk_penalty": args.risk_penalty,
                "leverage_limit": args.leverage_limit,
                "borrowing_cost": args.borrowing_cost,
                "trading_days_per_year": args.trading_days_per_year,
            },
            "progressive_base_steps": progressive_schedule,
        },
    }

    base_checkpoint_path: Path
    if args.skip_base:
        if not args.base_checkpoint:
            raise ValueError("--skip-base requires --base-checkpoint to be set")
        base_checkpoint_path = Path(args.base_checkpoint).expanduser().resolve()
        if not base_checkpoint_path.exists():
            raise FileNotFoundError(f"Base checkpoint '{base_checkpoint_path}' not found")
        summary["base_checkpoint"] = str(base_checkpoint_path)
        LOGGER.info("Skipping base stage; using checkpoint %s", base_checkpoint_path)
        processor_path = base_checkpoint_path.parent / "data_processor.pkl"
        if processor_path.exists():
            try:
                trainer.processor.load_scalers(str(processor_path))
                LOGGER.info("Loaded data processor scalers from %s", processor_path)
            except Exception as exc:  # noqa: BLE001
                LOGGER.warning("Failed to load processor scalers from %s: %s", processor_path, exc)
    else:
        LOGGER.info("Stage 1: training generic forecaster on %d symbols", len(base_symbols))
        progressive_schedule = (
            [int(val) for val in args.progressive_base_steps.split(",") if val.strip()]
            if args.progressive_base_steps
            else None
        )
        summary["config"]["progressive_base_steps"] = progressive_schedule

        model, checkpoint = trainer.train_base_model(
            max_steps=args.base_steps,
            batch_size=args.base_batch_size,
            learning_rate=args.base_learning_rate,
            progressive_schedule=progressive_schedule,
        )
        del model  # Model stays on disk; freeing memory
        base_checkpoint_path = Path(checkpoint)
        summary["base_checkpoint"] = checkpoint
        LOGGER.info("Base checkpoint saved to %s", checkpoint)

    if not args.skip_specialists:
        LOGGER.info("Stage 2: specialist fine-tuning for %d symbols", len(specialist_symbols))
        specialist_paths: Dict[str, str] = {}
        for symbol in specialist_symbols:
            LOGGER.info("Fine-tuning specialist for %s", symbol)
            model, path = trainer.finetune_for_stock(
                stock_symbol=symbol,
                base_checkpoint_path=str(base_checkpoint_path),
                num_epochs=args.finetune_epochs,
                learning_rate=args.finetune_learning_rate,
            )
            if model is None or path is None:
                LOGGER.warning("Specialist training for %s skipped or failed", symbol)
                continue
            del model
            specialist_paths[symbol] = path
            LOGGER.info("Specialist checkpoint for %s saved to %s", symbol, path)
        summary["specialists"] = specialist_paths
    else:
        LOGGER.info("Skipping specialist fine-tuning stage")

    if not args.skip_rl:
        LOGGER.info("Stage 3: differentiable portfolio RL on %d pairs", len(pairs))
        rl_config = PortfolioRLConfig(
            hidden_size=args.rl_hidden_size,
            num_layers=args.rl_num_layers,
            num_heads=args.rl_num_heads,
            dropout=0.1,
            learning_rate=args.rl_learning_rate,
            batch_size=args.rl_batch_size,
            epochs=args.rl_epochs,
            transaction_cost_bps=args.transaction_cost_bps,
            risk_penalty=args.risk_penalty,
            device=args.device,
            leverage_limit=args.leverage_limit,
            borrowing_cost=args.borrowing_cost,
            trading_days_per_year=args.trading_days_per_year,
        )
        pair_metrics: Dict[str, Dict[str, float]] = {}
        for sym_a, sym_b in pairs:
            LOGGER.info("Training allocation policy for pair %s/%s", sym_a, sym_b)
            metrics = trainer.train_pair_portfolio((sym_a, sym_b), rl_config=rl_config)
            pair_metrics[f"{sym_a}_{sym_b}"] = metrics
            LOGGER.info("Pair %s/%s metrics: %s", sym_a, sym_b, metrics)
        summary["portfolio_pairs"] = pair_metrics
    else:
        LOGGER.info("Skipping portfolio RL stage")

    return summary


def main() -> None:
    parser = build_argument_parser()
    args = parser.parse_args()
    _setup_logging(args.verbose)

    try:
        summary = run_pipeline(args)
    except Exception as exc:  # noqa: BLE001
        LOGGER.exception("Pipeline failed: %s", exc)
        raise SystemExit(1) from exc

    summary_path = Path(args.summary_path).expanduser().resolve()
    summary_path.parent.mkdir(parents=True, exist_ok=True)
    with summary_path.open("w") as handle:
        json.dump(summary, handle, indent=2)
    LOGGER.info("Pipeline summary written to %s", summary_path)
    LOGGER.info("Stages complete: base=%s, specialists=%s, portfolio=%s",
                not args.skip_base, not args.skip_specialists, not args.skip_rl)


if __name__ == "__main__":
    main()
