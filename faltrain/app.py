#!/usr/bin/env python3
"""
FAL training orchestration for the production trading stack.

Features:
    * Sync training data from R2 on startup, push artifacts back on completion.
    * Inject heavy dependencies into the training packages so imports stay fast.
    * Run HF / Toto / Puffer trainers sequentially on a GPU-H200 with sweep support.
    * Evaluate PnL for stock-only and stock+crypto configurations.
    * Upload best checkpoints + logs and return a JSON summary.
"""

from __future__ import annotations

import json
import logging
import math
import os
import random
import shutil
import subprocess
import warnings
import time
import uuid
from contextlib import nullcontext
from importlib import import_module
from pathlib import Path
from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple

import inspect

import copy
from collections import deque
from concurrent.futures import ThreadPoolExecutor, as_completed

import fal
import transformers
from pydantic import BaseModel, Field

from faltrain.artifacts import load_artifact_specs, sync_artifacts
from faltrain.batch_size_tuner import (
    BatchSizeSelection,
    auto_tune_batch_sizes,
    get_cached_batch_selection,
    persist_batch_size,
)
from faltrain.dependencies import bulk_register_fal_dependencies
from faltrain.logger_utils import configure_stdout_logging
from wandboard import WandBoardLogger

from src.dependency_injection import setup_imports as setup_src_imports
from src.tblib_compat import ensure_tblib_pickling_support
from src.torch_backend import configure_tf32_backends
from faltrain.shared_logger import get_logger, log_timing, setup_logging
REPO_ROOT = Path(__file__).resolve().parents[1]
ensure_tblib_pickling_support()
LOG = get_logger("faltrain.app", logging.INFO)

DEFAULT_STOCK_TRADING_FEE = 0.0005
DEFAULT_CRYPTO_TRADING_FEE = 0.0015
DEFAULT_STOCK_TRADING_FEE_BPS = int(round(DEFAULT_STOCK_TRADING_FEE * 10_000))
DEFAULT_CRYPTO_TRADING_FEE_BPS = int(round(DEFAULT_CRYPTO_TRADING_FEE * 10_000))

DEFAULT_STOCK_TRADING_FEE = 0.0005
DEFAULT_CRYPTO_TRADING_FEE = 0.0015
DEFAULT_STOCK_TRADING_FEE_BPS = int(round(DEFAULT_STOCK_TRADING_FEE * 10_000))
DEFAULT_CRYPTO_TRADING_FEE_BPS = int(round(DEFAULT_CRYPTO_TRADING_FEE * 10_000))

_TRAINING_INJECTION_MODULES: Tuple[str, ...] = (
    "hftraining.injection",
    "fal_hftraining.runner",
    "tototraining.injection",
    "pufferlibtraining.injection",
    "fal_pufferlibtraining.runner",
    "fal_marketsimulator.runner",
    "tototrainingfal.runner",
    "faltrain.batch_size_tuner",
)


def _env(key: str, default: Optional[str] = None) -> str:
    value = os.getenv(key, default)
    if value is None:
        raise RuntimeError(f"Missing required environment variable: {key}")
    return value


def _run(
    cmd: List[str],
    *,
    cwd: Path = REPO_ROOT,
    env: Optional[Dict[str, str]] = None,
    check: bool = True,
    capture: bool = False,
) -> subprocess.CompletedProcess:
    LOG.info("â€¢ $ %s", " ".join(cmd))
    run_kwargs: Dict[str, Any] = {
        "cwd": str(cwd),
        "env": env,
        "check": check,
        "text": True,
    }
    if capture:
        run_kwargs["stdout"] = subprocess.PIPE
        run_kwargs["stderr"] = subprocess.STDOUT
    return subprocess.run(cmd, **run_kwargs)


def _ensure_dir(path: Path) -> Path:
    path.mkdir(parents=True, exist_ok=True)
    return path


def _aws_sync(src: str, dst: str, endpoint: str, delete: bool = False) -> None:
    args = ["aws", "s3", "sync", src, dst, "--endpoint-url", endpoint]
    if delete:
        args.append("--delete")
    _run(args)


def _aws_cp(src: str, dst: str, endpoint: str, recursive: bool = False) -> None:
    args = ["aws", "s3", "cp", src, dst, "--endpoint-url", endpoint]
    if recursive:
        args.append("--recursive")
    _run(args)


def _resolve_training_seed(request_seed: Optional[int]) -> int:
    """Return the seed for a training run and seed relevant libraries."""
    seed = int(request_seed) if request_seed is not None else random.randint(1, 10_000_000)
    random.seed(seed)
    transformers.set_seed(seed)
    return seed


def _inject_training_modules(
    torch_mod: Any,
    numpy_mod: Any,
    pandas_mod: Any | None = None,
    *,
    module_names: Iterable[str] = _TRAINING_INJECTION_MODULES,
) -> None:
    for mod_path in module_names:
        try:
            module = import_module(mod_path)
        except ImportError:
            continue
        setup_fn = getattr(module, "setup_training_imports", None)
        if callable(setup_fn):
            try:
                params = tuple(inspect.signature(setup_fn).parameters.values())
            except (TypeError, ValueError):
                params = ()
            try:
                if len(params) >= 3:
                    setup_fn(torch_mod, numpy_mod, pandas_mod)
                else:
                    setup_fn(torch_mod, numpy_mod)
            except TypeError:
                setup_fn(torch_mod, numpy_mod)
            LOG.info("Injected torch/numpy into %s", mod_path)


_OOM_PATTERNS: Tuple[str, ...] = (
    "CUDA out of memory",
    "torch.cuda.OutOfMemoryError",
    "RuntimeError: CUDA out of memory",
    "CUDA error: out of memory",
    "CUBLAS error: CUBLAS_STATUS_ALLOC_FAILED",
    "out of memory",
    "Killed",
)


class TrainingOOMError(RuntimeError):
    def __init__(self, cmd: List[str], output: str) -> None:
        super().__init__("CUDA OOM while executing: " + " ".join(cmd))
        self.cmd = cmd
        self.output = output


def _looks_like_oom(output: str) -> bool:
    text = output.lower()
    for pattern in _OOM_PATTERNS:
        if pattern.lower() in text:
            return True
    return False


def _plan_to_selection(plan: Dict[str, Any], *, selected: int) -> Optional[BatchSizeSelection]:
    def _coerce_sequence(values: Any) -> Tuple[int, ...]:
        seq: List[int] = []
        if isinstance(values, (list, tuple)):
            for value in values:
                try:
                    seq.append(int(value))
                except (TypeError, ValueError):
                    continue
        return tuple(seq)

    descending = _coerce_sequence(plan.get("candidates_desc"))
    if not descending:
        descending = _coerce_sequence(plan.get("candidates"))
    if not descending:
        return None
    user_candidates = _coerce_sequence(plan.get("candidates_user"))
    if not user_candidates:
        user_candidates = descending
    signature = plan.get("signature")
    context_length = int(plan.get("context_length", 1))
    horizon = int(plan.get("horizon", 1))
    exhaustive = bool(plan.get("exhaustive", False))
    return BatchSizeSelection(
        signature=signature,
        selected=int(selected),
        descending_candidates=tuple(dict.fromkeys(descending)),
        user_candidates=tuple(dict.fromkeys(user_candidates)),
        context_length=context_length,
        horizon=horizon,
        exhaustive=exhaustive,
    )


def _score_from_metrics(metrics: Dict[str, Any]) -> Optional[float]:
    for key in ("val_loss", "validation_loss", "loss"):
        value = metrics.get(key)
        if isinstance(value, (int, float)):
            return float(value)
    return None


def _safe_number(value: Any) -> Optional[float]:
    if isinstance(value, (int, float)):
        result = float(value)
    elif isinstance(value, str):
        try:
            result = float(value.strip())
        except (TypeError, ValueError):
            return None
    else:
        return None
    if math.isnan(result) or math.isinf(result):
        return None
    return result


def _lookup_path(payload: Any, path: Iterable[str]) -> Any:
    current = payload
    for key in path:
        if isinstance(current, dict) and key in current:
            current = current[key]
        else:
            return None
    return current


def _extract_loss_metric(metrics: Dict[str, Any]) -> Optional[float]:
    if not isinstance(metrics, dict):
        return None

    preferred_paths = (
        ("val", "loss"),
        ("validation", "loss"),
        ("metrics", "val_loss"),
        ("metrics", "loss"),
        ("val_loss",),
        ("validation_loss",),
        ("best_val_loss",),
        ("loss",),
    )

    for path in preferred_paths:
        value = _lookup_path(metrics, path)
        number = _safe_number(value)
        if number is not None:
            return number

    # Fallback: breadth-first search for the first key containing "loss"
    queue: List[Any] = [metrics]
    while queue:
        current = queue.pop(0)
        if not isinstance(current, dict):
            continue
        for key, value in current.items():
            if isinstance(value, dict):
                queue.append(value)
            if isinstance(key, str) and "loss" in key.lower():
                number = _safe_number(value)
                if number is not None:
                    return number
    return None


def _extract_return_pct(pnl_summary: Dict[str, Any]) -> Optional[float]:
    if not isinstance(pnl_summary, dict):
        return None

    preferred_paths = (
        ("stock_only", "return_pct"),
        ("stock_plus_crypto", "return_pct"),
        ("return_pct",),
        ("test", "return_pct"),
        ("val", "return_pct"),
    )

    for path in preferred_paths:
        value = _lookup_path(pnl_summary, path)
        number = _safe_number(value)
        if number is not None:
            return number

    queue: List[Any] = [pnl_summary]
    while queue:
        current = queue.pop(0)
        if not isinstance(current, dict):
            continue
        for key, value in current.items():
            if isinstance(value, dict):
                queue.append(value)
            if isinstance(key, str) and "pnl" in key.lower():
                number = _safe_number(value)
                if number is not None:
                    return number
            if isinstance(key, str) and "return" in key.lower():
                number = _safe_number(value)
                if number is not None:
                    return number
    return None


def _sanitize_token(token: str) -> str:
    cleaned = token.strip().replace(os.sep, "-")
    cleaned = cleaned.replace(" ", "-")
    cleaned = cleaned.replace("__", "_")
    return cleaned or "model"


def _format_metric_token(prefix: str, value: Optional[float], precision: int) -> Optional[str]:
    if value is None:
        return None
    scaled = f"{value:.{precision}f}"
    scaled = scaled.rstrip("0").rstrip(".") or "0"
    token = f"{prefix}{scaled}"
    token = token.replace("+", "")
    return token


def _build_export_filename(
    *,
    source: Path,
    run_name: str,
    trainer: str,
    loss: Optional[float],
    return_pct: Optional[float],
    postfix: Optional[str] = None,
) -> str:
    tokens = [
        _sanitize_token(run_name),
        _sanitize_token(trainer),
        _sanitize_token(source.stem),
    ]
    if postfix:
        tokens.append(_sanitize_token(postfix))

    loss_token = _format_metric_token("loss", loss, 6)
    if loss_token:
        tokens.append(loss_token)

    pnl_token = _format_metric_token("pnl", return_pct, 2)
    if pnl_token:
        tokens.append(pnl_token)

    filename = "_".join(filter(None, tokens))
    return f"{filename}{source.suffix}"


def _collect_checkpoint_candidates(base_dir: Path) -> List[Path]:
    candidates: List[Path] = []
    seen: set[Path] = set()

    def _add(path: Path) -> None:
        if not path.exists():
            return
        try:
            resolved = path.resolve()
        except Exception:
            resolved = path
        if resolved in seen:
            return
        seen.add(resolved)
        candidates.append(path)

    priority_names = (
        "best_model.pt",
        "deployable.pt",
        "deployable_model.pt",
    )
    for name in priority_names:
        _add(base_dir / name)

    best_dir = base_dir / "best"
    if best_dir.is_dir():
        for path in sorted(best_dir.glob("rank*.pt")):
            _add(path)

    for path in sorted(base_dir.glob("*.pt"), key=lambda p: p.stat().st_mtime, reverse=True):
        _add(path)

    hf_export = base_dir / "hf_export"
    if hf_export.is_dir():
        for path in sorted(hf_export.glob("*.pt")):
            _add(path)

    return candidates


def _grid(space: "SweepSpace") -> List[Dict[str, Any]]:
    grid: List[Dict[str, Any]] = []
    batch_selection: Optional[BatchSizeSelection] = None
    if space.auto_tune_batch_size:
        batch_selection = get_cached_batch_selection(
            candidates=space.batch_sizes,
            context_lengths=space.context_lengths,
            horizons=space.horizons,
        )
        if batch_selection and batch_selection.signature:
            LOG.info(
                "Reusing cached batch size %s for signature %s",
                batch_selection.selected,
                batch_selection.signature,
            )
    if batch_selection is None:
        batch_selection = auto_tune_batch_sizes(
            candidates=space.batch_sizes,
            context_lengths=space.context_lengths,
            horizons=space.horizons,
            auto_tune=space.auto_tune_batch_size,
            safety_margin=space.batch_size_safety_margin,
        )
    batch_meta = batch_selection.meta()
    for lr in space.learning_rates:
        for bs in batch_selection.sweep_values():
            fallbacks = batch_selection.fallback_values(start=bs)
            for cl in space.context_lengths:
                for horizon in space.horizons:
                    for loss in space.loss:
                        for crypto_enabled in space.crypto_enabled:
                            cfg = {
                                "learning_rate": lr,
                                "batch_size": bs,
                                "context_length": cl,
                                "horizon": horizon,
                                "loss": loss,
                                "crypto_enabled": crypto_enabled,
                                "batch_size_plan": {
                                    **batch_meta,
                                    "initial": bs,
                                    "fallbacks": fallbacks,
                                },
                            }
                            grid.append(cfg)
    return grid


class SweepSpace(BaseModel):
    learning_rates: List[float] = [7e-4, 3e-4]
    batch_sizes: List[int] = [2048, 1024, 512, 256]
    context_lengths: List[int] = [512, 1024]
    horizons: List[int] = [30, 60]
    loss: List[str] = ["mse"]
    crypto_enabled: List[bool] = [False, True]
    auto_tune_batch_size: bool = True
    batch_size_safety_margin: float = 0.8


class TrainRequest(BaseModel):
    run_name: str = Field(default_factory=lambda: f"run_{int(time.time())}")
    trainer: str = Field("hf", description="hf | toto | puffer")
    trainingdata_prefix: str = "trainingdata"
    output_root: str = "/data/experiments"
    do_sweeps: bool = False
    sweeps: SweepSpace = SweepSpace()
    symbols: List[str] = ["SPY"]
    val_days: int = 30
    epochs: int = 2
    transaction_cost_bps: Optional[int] = None
    stock_transaction_cost_bps: int = DEFAULT_STOCK_TRADING_FEE_BPS
    crypto_transaction_cost_bps: int = DEFAULT_CRYPTO_TRADING_FEE_BPS
    seed: Optional[int] = None
    parallel_trials: int = 4


class RunArtifact(BaseModel):
    local_dir: str
    r2_uri: Optional[str] = None
    metrics_path: Optional[str] = None


class SweepResult(BaseModel):
    cfg: Dict[str, Any]
    metrics: Dict[str, Any]
    artifacts: RunArtifact


class TrainResponse(BaseModel):
    run_name: str
    best_cfg: Dict[str, Any]
    best_metrics: Dict[str, Any]
    sweep_results: List[SweepResult]
    pnl_summary: Dict[str, Any]
    artifact_root: RunArtifact


def _resolve_transaction_cost_bps(req: TrainRequest, *, crypto_enabled: bool) -> int:
    if req.transaction_cost_bps is not None:
        return int(req.transaction_cost_bps)
    if crypto_enabled:
        return int(req.crypto_transaction_cost_bps)
    return int(req.stock_transaction_cost_bps)


class StockTrainerApp(
    fal.App,
    name="stock-trainer",
    min_concurrency=0,
    max_concurrency=1,
    keep_alive=30,
):
    machine_type = "GPU-H200"
    python_version = "3.12"
    requirements = [
        "fal-client",
        "tblib>=3.2",
        "nvidia-ml-py>=13.580.82",
        "torch>=2.8.0",
        "torchvision>=0.21.0",
        "numpy>=1.24.4,<2",
        "pandas",
        "tqdm",
        "rich",
        "orjson",
        "awscli",
        "boto3",
        "huggingface-hub[cli]",
        "safetensors",
        "transformers>=4.45.0",
        "accelerate>=1.2.0",
        "bitsandbytes>=0.44.0",
        "xformers",
        "wandb",
    ]
    local_python_modules: List[str] = [
        "faltrain",
        "hftraining",
        "hfshared",
        "hfinference",
        "traininglib",
        "marketsimulator",
        "differentiable_market",
        "toto",
        "pufferlibtraining",
        "pufferlibinference",
        "gymrl",
        "src",
        "fal_hftraining",
        "fal_pufferlibtraining",
    ]

    def setup(self) -> None:
        setup_logging(logging.INFO)
        configure_stdout_logging(level=logging.INFO, fmt="%(asctime)s | %(message)s")
        with log_timing(LOG, "StockTrainerApp.setup"):
            warnings.filterwarnings(
                "ignore",
                message="The pynvml package is deprecated.*",
                category=FutureWarning,
                module="torch.cuda",
            )
            LOG.info(
                "Starting StockTrainerApp.setup pid=%s cwd=%s",
                os.getpid(),
                os.getcwd(),
            )
            os.environ.setdefault("CUDA_LAUNCH_BLOCKING", "0")
            os.environ.setdefault(
                "PYTORCH_CUDA_ALLOC_CONF", "max_split_size_mb:1024,expandable_segments:True"
            )
            LOG.debug(
                "Environment CUDA_LAUNCH_BLOCKING=%s PYTORCH_CUDA_ALLOC_CONF=%s",
                os.getenv("CUDA_LAUNCH_BLOCKING"),
                os.getenv("PYTORCH_CUDA_ALLOC_CONF"),
            )

            with log_timing(LOG, "Import torch/numpy/pandas"):
                import torch as _torch
                import numpy as _np
                import pandas as _pd

            with log_timing(LOG, "Configure torch backends"):
                tf32_state = configure_tf32_backends(_torch, logger=LOG)
                LOG.info(
                    "TF32 precision configured new_api=%s legacy_api=%s",
                    tf32_state["new_api"],
                    tf32_state["legacy_api"],
                )
                try:
                    _torch.backends.cudnn.benchmark = True
                    _torch.backends.cuda.enable_flash_sdp(True)
                    _torch.backends.cuda.enable_math_sdp(True)
                    _torch.backends.cuda.enable_mem_efficient_sdp(True)
                except Exception:
                    LOG.debug("Skipping advanced CUDA backend configuration", exc_info=True)

            with log_timing(LOG, "Register shared dependencies"):
                bulk_register_fal_dependencies(
                    {
                        "torch": _torch,
                        "numpy": _np,
                        "pandas": _pd,
                    }
                )
                setup_src_imports(_torch, _np, _pd)
                _inject_training_modules(_torch, _np, _pd)

            with log_timing(LOG, "Prepare training directories"):
                _ensure_dir(Path("/data"))
                _ensure_dir(Path("/data/trainingdata"))
                _ensure_dir(Path("/data/experiments"))

            with log_timing(LOG, "Prefetch reference artifacts"):
                self._prefetch_reference_artifacts()

            LOG.info(
                "StockTrainerApp setup complete cuda_available=%s device='%s' torch=%s",
                _torch.cuda.is_available(),
                _torch.cuda.get_device_name(0) if _torch.cuda.is_available() else "cpu",
                _torch.__version__,
            )

    def _prefetch_reference_artifacts(self) -> None:
        try:
            endpoint = _env("R2_ENDPOINT")
        except RuntimeError as exc:
            LOG.warning("Skipping reference artifact download (missing endpoint): %s", exc)
            return

        bucket = os.getenv("R2_BUCKET", "models")
        try:
            specs = load_artifact_specs(repo_root=REPO_ROOT)
        except Exception as exc:
            LOG.warning("Failed to load artifact manifest: %s", exc)
            return

        if not specs:
            LOG.info("No artifact specs configured; skipping reference fetch")
            return

        try:
            sync_artifacts(
                specs,
                direction="download",
                bucket=bucket,
                endpoint_url=endpoint,
                local_root=REPO_ROOT,
                skip_existing=True,
            )
        except Exception as exc:
            LOG.warning("Failed to prefetch reference artifacts: %s", exc)

    def _invoke_training_process(
        self,
        cmd: List[str],
        *,
        env: Optional[Dict[str, str]] = None,
    ) -> str:
        tail = deque(maxlen=200)
        oom_hint = False
        try:
            proc = subprocess.Popen(
                cmd,
                cwd=str(REPO_ROOT),
                env=env,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
            )
        except Exception as exc:
            raise RuntimeError(f"Failed to start training command {cmd}: {exc}") from exc

        assert proc.stdout is not None
        with proc.stdout:
            for raw_line in proc.stdout:
                line = raw_line.rstrip("\n")
                LOG.info(line)
                tail.append(line)
                if not oom_hint and _looks_like_oom(line):
                    oom_hint = True
        return_code = proc.wait()
        summary = "\n".join(tail)
        if not oom_hint and summary:
            oom_hint = _looks_like_oom(summary)
        if return_code != 0:
            if oom_hint:
                raise TrainingOOMError(cmd, summary)
            raise RuntimeError(
                f"Training command failed (exit={return_code}): {' '.join(cmd)}\n{summary}"
            )
        return summary

    def _run_with_batch_retry(
        self,
        runner: Callable[[Dict[str, Any]], Tuple[Dict[str, Any], Path]],
        cfg: Dict[str, Any],
    ) -> Tuple[Dict[str, Any], Path]:
        plan = cfg.get("batch_size_plan")
        fallback_values: List[int] = []
        if isinstance(plan, dict):
            for value in plan.get("fallbacks", []):
                try:
                    fallback_values.append(int(value))
                except (TypeError, ValueError):
                    continue
        if not fallback_values:
            fallback_values = [int(cfg["batch_size"])]

        last_exc: Optional[TrainingOOMError] = None
        for batch_size in fallback_values:
            cfg["batch_size"] = int(batch_size)
            LOG.info("Launching training with batch_size=%s", batch_size)
            try:
                metrics, outdir = runner(cfg)
            except TrainingOOMError as exc:
                LOG.warning(
                    "CUDA OOM detected for batch_size=%s; falling back to smaller candidate",
                    batch_size,
                )
                if isinstance(plan, dict):
                    plan.setdefault("oom_attempts", []).append(batch_size)
                last_exc = exc
                continue

            if isinstance(plan, dict):
                plan["used"] = batch_size
                selection = _plan_to_selection(plan, selected=batch_size)
                if selection is not None:
                    try:
                        persist_batch_size(selection, batch_size=batch_size)
                    except Exception as exc:
                        LOG.warning(
                            "Failed to persist successful batch size %s: %s", batch_size, exc
                        )
            return metrics, outdir

        if last_exc is not None:
            raise last_exc
        raise RuntimeError("Batch size retry logic exhausted without attempting training")

    def _runner_for_request(
        self, request: TrainRequest, artifact_root: Path
    ) -> Callable[[Dict[str, Any]], Tuple[Dict[str, Any], Path]]:
        if request.trainer == "hf":
            return lambda cfg: self._run_hf_once(artifact_root, request, cfg)
        if request.trainer == "toto":
            return lambda cfg: self._run_toto_once(artifact_root, request, cfg)
        if request.trainer == "puffer":
            return lambda cfg: self._run_puffer_once(artifact_root, request, cfg)
        raise ValueError(f"Unknown trainer: {request.trainer}")

    def _run_single_config(
        self,
        idx: int,
        total: int,
        cfg: Dict[str, Any],
        runner: Callable[[Dict[str, Any]], Tuple[Dict[str, Any], Path]],
    ) -> Tuple[int, Dict[str, Any], Dict[str, Any], Path, float]:
        cfg_local = copy.deepcopy(cfg)
        LOG.info("=== Sweep %d/%d ===", idx + 1, total)
        LOG.info("Config: %s", cfg_local)
        start_ts = time.time()
        metrics, outdir = self._run_with_batch_retry(runner, cfg_local)
        duration = time.time() - start_ts
        return idx, cfg_local, metrics, outdir, duration

    def _run_hf_once(
        self, workdir: Path, req: TrainRequest, cfg: Dict[str, Any]
    ) -> Tuple[Dict[str, Any], Path]:
        run_id = uuid.uuid4().hex[:8]
        outdir = _ensure_dir(workdir / f"hf_{run_id}")

        config = {
            "seed": cfg.get("seed", req.seed or 42),
            "training": {
                "epochs": req.epochs,
                "batch_size": cfg["batch_size"],
                "learning_rate": cfg["learning_rate"],
                "loss": cfg["loss"],
                "transaction_cost_bps": int(
                    cfg.get(
                        "transaction_cost_bps",
                        _resolve_transaction_cost_bps(
                            req, crypto_enabled=cfg.get("crypto_enabled", False)
                        ),
                    )
                ),
            },
            "data": {
                "symbols": req.symbols,
                "context_length": cfg["context_length"],
                "horizon": cfg["horizon"],
                "val_days": req.val_days,
                "trainingdata_dir": req.trainingdata_prefix,
                "use_toto_forecasts": cfg.get("crypto_enabled", False),
            },
            "costs": {"transaction_cost_bps": req.transaction_cost_bps},
            "output": {"dir": str(outdir)},
        }

        cfg_path = outdir / "config.json"
        with cfg_path.open("w") as handle:
            json.dump(config, handle, indent=2)

        os.environ.setdefault("WANDB_PROJECT", _env("WANDB_PROJECT", "stock-prediction"))
        os.environ.setdefault("WANDB_ENTITY", _env("WANDB_ENTITY", "default"))
        os.environ.setdefault("WANDB_RUN_GROUP", req.run_name)

        from fal_hftraining.runner import run_training as run_hf_training

        metrics, _ = run_hf_training(config=config, run_name=req.run_name, output_dir=outdir)
        return metrics, outdir

    def _run_toto_once(
        self, workdir: Path, req: TrainRequest, cfg: Dict[str, Any]
    ) -> Tuple[Dict[str, Any], Path]:
        run_id = uuid.uuid4().hex[:8]
        outdir = _ensure_dir(workdir / f"toto_{run_id}")
        from tototrainingfal.runner import run_training as run_toto_training

        trainingdata_root = Path(req.trainingdata_prefix)
        train_root = trainingdata_root / "train"
        val_root = trainingdata_root / "val"
        if not val_root.exists():
            alt = trainingdata_root / "test"
            val_root = alt if alt.exists() else None

        device_label = "cuda"
        try:
            import torch  # type: ignore

            if not torch.cuda.is_available():
                device_label = "cpu"
        except Exception:
            device_label = "cpu"

        metrics, _ = run_toto_training(
            train_root=train_root,
            val_root=val_root,
            context_length=int(cfg["context_length"]),
            prediction_length=int(cfg["horizon"]),
            stride=int(max(1, cfg["horizon"])),
            batch_size=int(cfg["batch_size"]),
            epochs=int(req.epochs),
            learning_rate=float(cfg.get("learning_rate", req.sweeps.learning_rates[0])),
            loss=str(cfg["loss"]),
            output_dir=outdir,
            device=device_label,
            grad_accum=max(1, cfg.get("grad_accum", 1)),
        )

        return metrics, outdir

    def _run_puffer_once(
        self, workdir: Path, req: TrainRequest, cfg: Dict[str, Any]
    ) -> Tuple[Dict[str, Any], Path]:
        run_id = uuid.uuid4().hex[:8]
        outdir = _ensure_dir(workdir / f"puffer_{run_id}")
        logdir = _ensure_dir(outdir / "logs")

        from fal_pufferlibtraining.runner import run_training as run_puffer_training

        summary, summary_path = run_puffer_training(
            trainingdata_dir=Path(req.trainingdata_prefix),
            output_dir=outdir,
            tensorboard_dir=logdir,
            cfg=cfg,
            epochs=req.epochs,
            transaction_cost_bps=float(cfg.get("transaction_cost_bps", req.transaction_cost_bps or 0)),
            run_name=req.run_name,
        )

        metrics: Dict[str, Any] = {}
        if summary_path.exists():
            try:
                metrics = json.loads(summary_path.read_text()).get("portfolio_pairs", {})
            except json.JSONDecodeError:
                metrics = {}
        if not metrics:
            metrics = summary.get("portfolio_pairs", {})
        return metrics, outdir

    def _evaluate_pnl(
        self, model_dir: Path, include_crypto: bool, trainingdata_dir: Path
    ) -> Dict[str, Any]:
        pnl = {
            "return_pct": None,
            "sharpe": None,
            "max_drawdown_pct": None,
            "mode": "hf_quick_realistic_test",
        }
        try:
            from hftraining.quick_realistic_test import quick_test

            _, metrics, _ = quick_test()
            if metrics is not None:
                pnl["return_pct"] = float(getattr(metrics, "total_return", 0.0) * 100.0)
                pnl["sharpe"] = float(getattr(metrics, "sharpe_ratio", 0.0))
                pnl["max_drawdown_pct"] = float(getattr(metrics, "max_drawdown", 0.0) * 100.0)
        except Exception:
            pass

        try:
            from comprehensive_backtest_real_gpu import ComprehensiveBacktester
            from src.fixtures import crypto_symbols

            symbols = [
                "COUR",
                "GOOG",
                "TSLA",
                "NVDA",
                "AAPL",
                "U",
                "ADSK",
                "ADBE",
                "COIN",
                "MSFT",
                "NFLX",
            ]
            if include_crypto:
                symbols.extend(symbol for symbol in crypto_symbols[:3])
            backtester = ComprehensiveBacktester(symbols=symbols)
            backtester.run_comprehensive_backtest()
        except Exception:
            pass

        try:
            from enhanced_local_backtester import run_enhanced_comparison
            from src.fixtures import crypto_symbols

            symbols = ["AAPL", "MSFT", "NVDA", "GOOGL", "TSLA"]
            if include_crypto:
                symbols.extend(symbol for symbol in crypto_symbols[:2])
            run_enhanced_comparison(symbols, simulation_days=14, compare_with_synthetic=False)
        except Exception:
            pass

        LOG.info("PnL summary (crypto=%s): %s", include_crypto, pnl)
        return pnl

    def _export_best_model(
        self,
        *,
        best: SweepResult,
        pnl_summary: Dict[str, Any],
        trainer: str,
        run_name: str,
        s3_uri: str,
        endpoint: str,
    ) -> Optional[Path]:
        best_dir = Path(best.artifacts.local_dir)
        if not best_dir.exists():
            LOG.info("Best artifact directory %s missing; skipping model export", best_dir)
            return None

        candidates = _collect_checkpoint_candidates(best_dir)
        if not candidates:
            LOG.info("No checkpoint artifacts under %s; skipping model export", best_dir)
            return None

        loss_metric = _extract_loss_metric(best.metrics)
        pnl_metric = _extract_return_pct(pnl_summary)

        models_dir = _ensure_dir(Path(os.getenv("FALTRAIN_MODELS_DIR", "/data/models")))
        source = candidates[0]
        filename = _build_export_filename(
            source=source,
            run_name=run_name,
            trainer=trainer,
            loss=loss_metric,
            return_pct=pnl_metric,
        )
        destination = models_dir / filename

        LOG.info("Exporting compiled model %s -> %s", source, destination)
        shutil.copy2(source, destination)

        remote_uri = f"{s3_uri}/models/{filename}"
        LOG.info("Uploading compiled model to %s", remote_uri)
        _aws_cp(str(destination), remote_uri, endpoint)

        return destination

    @fal.endpoint("/api/train")
    def train(self, request: TrainRequest) -> TrainResponse:
        r2_endpoint = _env("R2_ENDPOINT")
        bucket = _env("R2_BUCKET", "models")
        s3_uri = f"s3://{bucket}"

        local_data = Path("/data/trainingdata")
        remote_data = f"{s3_uri}/trainingdata/"
        LOG.info("Syncing training data from %s", remote_data)
        _aws_sync(remote_data, f"{local_data}/", r2_endpoint)

        repo_trainingdata = (REPO_ROOT / request.trainingdata_prefix).resolve()
        if not repo_trainingdata.exists():
            repo_trainingdata.parent.mkdir(parents=True, exist_ok=True)
            try:
                if repo_trainingdata.exists() or repo_trainingdata.is_symlink():
                    repo_trainingdata.unlink()
            except FileNotFoundError:
                pass
            try:
                os.symlink(local_data, repo_trainingdata)
                LOG.info("Symlinked training data -> %s", repo_trainingdata)
            except FileExistsError:
                pass

        seed = _resolve_training_seed(request.seed)
        base_cfg = {"seed": seed}
        sweep_cfgs = [base_cfg]
        if request.do_sweeps:
            sweep_cfgs = [{**base_cfg, **grid} for grid in _grid(request.sweeps)]
        else:
            sweep_cfgs = [{**base_cfg, **_grid(request.sweeps)[0]}]

        for cfg in sweep_cfgs:
            crypto_flag = bool(cfg.get("crypto_enabled", False))
            cfg.setdefault("crypto_enabled", crypto_flag)
            cfg["transaction_cost_bps"] = _resolve_transaction_cost_bps(
                request, crypto_enabled=crypto_flag
            )

        artifact_root = _ensure_dir(Path(request.output_root) / request.run_name)
        runner = self._runner_for_request(request, artifact_root)
        total_runs = len(sweep_cfgs)
        parallel_trials = max(1, min(int(request.parallel_trials or 1), total_runs))

        enable_sweep_logging = request.do_sweeps and total_runs > 1
        sweep_logger_ctx = nullcontext(None)
        if enable_sweep_logging:
            aggregate_log_dir = _ensure_dir(artifact_root / "sweep_logs")
            try:
                sweep_logger_ctx = WandBoardLogger(
                    run_name=f"{request.run_name}_sweep",
                    project=os.getenv("WANDB_PROJECT"),
                    entity=os.getenv("WANDB_ENTITY"),
                    group=request.run_name,
                    tags=(f"trainer:{request.trainer}", "faltrain", "sweep"),
                    log_dir=aggregate_log_dir,
                    tensorboard_subdir="aggregate",
                    enable_wandb=True,
                )
            except Exception as exc:
                LOG.warning("Failed to initialise sweep logger: %s", exc)
                sweep_logger_ctx = nullcontext(None)
                enable_sweep_logging = False

        results_by_idx: Dict[int, Tuple[Dict[str, Any], Dict[str, Any], Path, float, float]] = {}
        pnl_per_idx: Dict[int, Dict[str, Dict[str, Any]]] = {}
        results: List[SweepResult] = []
        best_idx, best_score = -1, float("inf")

        with sweep_logger_ctx as sweep_logger:

            def _record_result(
                idx_res: int,
                cfg_res: Dict[str, Any],
                metrics_res: Dict[str, Any],
                outdir_res: Path,
                duration_res: float,
            ) -> None:
                nonlocal best_idx, best_score
                score_val = _score_from_metrics(metrics_res)
                score = score_val if score_val is not None else float("inf")
                score_display = score_val if score_val is not None else "n/a"
                LOG.info(
                    "Run finished in %.1fs with score=%s (artifacts=%s)",
                    duration_res,
                    score_display,
                    outdir_res,
                )
                results_by_idx[idx_res] = (cfg_res, metrics_res, outdir_res, score, duration_res)
                if best_idx == -1 or score < best_score:
                    best_score = score
                    best_idx = idx_res

            if parallel_trials == 1:
                for idx, cfg in enumerate(sweep_cfgs):
                    idx_res, cfg_res, metrics_res, outdir_res, duration_res = self._run_single_config(
                        idx, total_runs, cfg, runner
                    )
                    _record_result(idx_res, cfg_res, metrics_res, outdir_res, duration_res)
            else:
                with ThreadPoolExecutor(max_workers=parallel_trials) as executor:
                    futures = [
                        executor.submit(self._run_single_config, idx, total_runs, cfg, runner)
                        for idx, cfg in enumerate(sweep_cfgs)
                    ]
                    try:
                        for future in as_completed(futures):
                            idx_res, cfg_res, metrics_res, outdir_res, duration_res = future.result()
                            _record_result(idx_res, cfg_res, metrics_res, outdir_res, duration_res)
                    except Exception:
                        for future in futures:
                            future.cancel()
                        raise

            if best_idx == -1:
                raise RuntimeError("No training runs completed successfully")

            for idx in sorted(results_by_idx):
                cfg_res, metrics_res, outdir_res, score_res, _ = results_by_idx[idx]
                metrics_file = None
                outdir_path = Path(outdir_res)
                for candidate in ("final_metrics.json", "summary.json"):
                    candidate_path = outdir_path / candidate
                    if candidate_path.exists():
                        metrics_file = str(candidate_path)
                        break
                results.append(
                    SweepResult(
                        cfg=cfg_res,
                        metrics=metrics_res,
                        artifacts=RunArtifact(
                            local_dir=str(outdir_res),
                            metrics_path=metrics_file,
                        ),
                    )
                )

                should_eval_pnl = enable_sweep_logging or idx == best_idx
                if should_eval_pnl:
                    pnl_per_idx[idx] = {
                        "stock_only": self._evaluate_pnl(
                            Path(outdir_res), include_crypto=False, trainingdata_dir=local_data
                        ),
                        "stock_plus_crypto": self._evaluate_pnl(
                            Path(outdir_res), include_crypto=True, trainingdata_dir=local_data
                        ),
                    }

            if sweep_logger:
                table_name = f"{request.trainer}_sweep"
                for idx in sorted(results_by_idx):
                    cfg_res, metrics_res, outdir_res, score_res, duration_res = results_by_idx[idx]
                    combined_metrics: Dict[str, Any] = {"duration_seconds": duration_res}
                    if metrics_res:
                        combined_metrics["training"] = metrics_res
                    if math.isfinite(score_res):
                        combined_metrics["score"] = score_res
                    if idx in pnl_per_idx:
                        combined_metrics["pnl"] = pnl_per_idx[idx]
                    combined_metrics["artifacts_dir"] = str(outdir_res)
                    sweep_logger.log_sweep_point(
                        hparams=cfg_res,
                        metrics=combined_metrics,
                        step=idx,
                        table_name=table_name,
                    )

        if best_idx == -1:
            raise RuntimeError("No training runs completed successfully")

        best = results[best_idx]
        if best_idx in pnl_per_idx:
            pnl_summary = pnl_per_idx[best_idx]
        else:
            pnl_summary = {
                "stock_only": self._evaluate_pnl(
                    Path(best.artifacts.local_dir), include_crypto=False, trainingdata_dir=local_data
                ),
                "stock_plus_crypto": self._evaluate_pnl(
                    Path(best.artifacts.local_dir), include_crypto=True, trainingdata_dir=local_data
                ),
            }

        LOG.info("Uploading artifacts for run %s", request.run_name)
        run_prefix = f"{s3_uri}/checkpoints/{request.run_name}/"
        _aws_cp(f"{artifact_root}/", run_prefix, r2_endpoint, recursive=True)

        logs_dir = artifact_root / "logs"
        if logs_dir.is_dir():
            _aws_cp(f"{logs_dir}/", f"{s3_uri}/logs/{request.run_name}/", r2_endpoint, recursive=True)

        exported_model = self._export_best_model(
            best=best,
            pnl_summary=pnl_summary,
            trainer=request.trainer,
            run_name=request.run_name,
            s3_uri=s3_uri,
            endpoint=r2_endpoint,
        )
        if exported_model is not None:
            LOG.info("Exported compiled model available at %s", exported_model)

        return TrainResponse(
            run_name=request.run_name,
            best_cfg=best.cfg,
            best_metrics=best.metrics,
            sweep_results=results,
            pnl_summary=pnl_summary,
            artifact_root=RunArtifact(local_dir=str(artifact_root), r2_uri=run_prefix),
        )


# Ensure the fal runtime sees concrete annotations when introspecting endpoints.
StockTrainerApp.train.__annotations__ = {
    **StockTrainerApp.train.__annotations__,
    "request": TrainRequest,
    "return": TrainResponse,
}


def create_app() -> StockTrainerApp:
    if os.getenv("IS_ISOLATE_AGENT"):
        return StockTrainerApp()
    return StockTrainerApp(_allow_init=True)


app = create_app()
