# Speed Optimization Findings

Results from benchmarking different optimizer configurations to find the fastest way to maximize P&L.

## Executive Summary

**Key Finding:** DIRECT_fast provides **6x speedup** over DIRECT_thorough with only **28% quality loss**, making it ideal for rapid iteration.

**For Production:**
- Use `DIRECT` with `maxfun=100-200` for fast optimization (2-3ms per optimization)
- Keep current `DIRECT` default (`maxfun=500`) for production (7-8ms, best balance)
- **Don't use multicore DE** - overhead dominates for small problems
- **Do use multicore** for running many optimizations in parallel (benchmark harness level)

## DIRECT Configuration Benchmarks

Tested 4 DIRECT configurations on synthetic P&L problems (5 trials each):

| Configuration | Speed (ms) | Speedup | Quality Loss | Evaluations | Best For |
|---------------|-----------|---------|--------------|-------------|----------|
| **DIRECT_ultra_fast** | 0.81 | 16.5x | 50.6% | 51 | Quick prototyping |
| **DIRECT_fast** | 2.21 | 6.0x | **27.8%** | 102 | **Rapid iteration** â­ |
| **DIRECT_default** | 6.59 | 2.0x | 7.8% | 503 | **Production** â­ |
| **DIRECT_thorough** | 13.36 | 1.0x | 0.0% | 1001 | High-stakes optimization |

### Recommendations by Use Case

**Development/Testing:**
```python
# Fast iteration - 2.2ms per optimization
config = BenchmarkConfig(
    bounds=[(-0.03, 0.03), (-0.03, 0.03)],
    maxiter=50,
    popsize=10,
    function_budget=100,  # DIRECT: maxfun=100
)
```

**Production (Current):**
```python
# Best balance - 6.6ms per optimization
config = BenchmarkConfig(
    bounds=[(-0.03, 0.03), (-0.03, 0.03)],
    maxiter=50,
    popsize=10,
    function_budget=500,  # DIRECT: maxfun=500 (current default)
)
```

**High-Stakes:**
```python
# Maximum quality - 13.4ms per optimization
config = BenchmarkConfig(
    bounds=[(-0.03, 0.03), (-0.03, 0.03)],
    maxiter=50,
    popsize=10,
    function_budget=1000,  # DIRECT: maxfun=1000
)
```

## Differential Evolution Parallel Scaling

**Surprising Result:** Parallel DE is **slower** for small problems due to multiprocessing overhead.

| Configuration | Workers | Speed (ms) | Speedup | Quality |
|---------------|---------|-----------|---------|---------|
| DE_sequential | 1 | 62.9 | 1.0x (baseline) | Best |
| DE_2workers | 2 | 155.9 | **0.4x** âŒ | Similar |
| DE_4workers | 4 | 203.5 | **0.3x** âŒ | Similar |
| DE_8workers | 8 | 246.2 | **0.3x** âŒ | Similar |
| DE_allcores | -1 | 1675.3 | **0.04x** âŒ | Similar |

### Why Parallel DE is Slower

1. **Multiprocessing overhead** dominates for small/fast objective functions
2. **Process spawning** takes longer than the actual optimization
3. **Communication costs** between workers add latency
4. **Small problem size** - each evaluation is ~100-500Î¼s, too fast to parallelize

### When to Use Parallel DE

Parallel DE **is beneficial** when:
- Objective function is expensive (>10ms per evaluation)
- Running on large datasets (minutes per evaluation)
- Optimizing neural network hyperparameters
- Using simulation-heavy fitness functions

Parallel DE **is NOT beneficial** when:
- Objective function is fast (<1ms per evaluation)
- Small search spaces (2-5 dimensions)
- Quick torch-based calculations (like our P&L optimization)

## Correct Parallelization Strategy

### âŒ Wrong: Parallelize Individual Optimizations
```python
# DON'T DO THIS - overhead dominates
result = differential_evolution(
    objective_fn,
    bounds=bounds,
    workers=8,  # âŒ Slower for fast objectives!
)
```

### âœ… Right: Parallelize Multiple Optimizations
```python
# DO THIS - parallelize at benchmark level
with ProcessPoolExecutor(max_workers=8) as executor:
    futures = {}
    for symbol in symbols:  # Many optimizations
        future = executor.submit(optimize_strategy, symbol)
        futures[future] = symbol

    for future in as_completed(futures):
        result = future.result()  # Each uses sequential optimizer
```

## Performance Implications for Real Use

### Scenario 1: Backtest 100 Symbols

**Current Approach (Sequential):**
- 100 symbols Ã— 6.6ms per optimization = 660ms total
- Single-threaded

**Optimized Approach (Parallel Backtests):**
- 100 symbols Ã· 8 workers = 12.5 batches
- 12.5 Ã— 6.6ms = **83ms total**
- **8x speedup** from parallelizing backtests, not individual optimizations

### Scenario 2: Hyperparameter Search (50 Configs)

**Current:**
- 50 configs Ã— 6.6ms = 330ms

**With DIRECT_fast:**
- 50 configs Ã— 2.2ms = 110ms
- **3x speedup**

**With Parallel + DIRECT_fast:**
- 50 configs Ã· 8 workers Ã— 2.2ms = **14ms total**
- **24x speedup**

## Speedup Summary

| Technique | Speedup | When to Use |
|-----------|---------|-------------|
| DIRECT_fast vs DIRECT_thorough | 6x | Always for development |
| Parallel benchmarks (8 workers) | 8x | Multiple symbols/configs |
| Both combined | **48x** | Large hyperparameter searches |

## Update Recommendations

### 1. Add Fast Mode to optimization_utils.py

```python
# Add to optimization_utils.py
_FAST_MODE = os.getenv("MARKETSIM_FAST_OPTIMIZATION", "0") in {"1", "true", "yes"}

def optimize_entry_exit_multipliers(...):
    if _USE_DIRECT:
        maxfun = 100 if _FAST_MODE else 500  # 6x faster for development
        result = direct(objective, bounds=bounds, maxfun=maxfun)
```

### 2. Use Parallel Backtest Runner

Already implemented in `parallel_backtest_runner.py` - use this pattern:
```bash
python parallel_backtest_runner.py AAPL MSFT NVDA --workers 8
```

### 3. Environment Variables

```bash
# Fast mode for development
export MARKETSIM_FAST_OPTIMIZATION=1
export MARKETSIM_USE_DIRECT_OPTIMIZER=1  # Already default

# Production mode (default)
export MARKETSIM_FAST_OPTIMIZATION=0
export MARKETSIM_USE_DIRECT_OPTIMIZER=1
```

## Benchmark Commands

```bash
# Test DIRECT configurations
python strategytraining/benchmark_speed_optimization.py \
    --mode direct --num-trials 5 --workers 8

# Test DE parallelism
python strategytraining/benchmark_speed_optimization.py \
    --mode de-parallel --num-trials 5 --workers 8

# Full comparison
python strategytraining/benchmark_speed_optimization.py \
    --mode full --num-trials 5 --workers 8
```

## Next Steps

1. âœ… **Use DIRECT_fast** for development (set `maxfun=100`)
2. âœ… **Keep current defaults** for production (`maxfun=500`)
3. âœ… **Avoid parallel DE** for P&L optimization (overhead dominates)
4. âœ… **Use parallel backtests** for multi-symbol optimization (8x speedup)
5. ðŸ”„ **Test on real P&L data** to validate findings
6. ðŸ”„ **Add FAST_MODE environment variable** to optimization_utils.py

## Files Created

- `strategytraining/benchmark_speed_optimization.py` - Speed-focused benchmarking
- `strategytraining/benchmark_optimizers.py` - Multi-optimizer comparison
- `strategytraining/benchmark_on_real_pnl.py` - Real P&L testing
- `strategytraining/analyze_optimizer_benchmarks.py` - Results analysis

## References

- DIRECT algorithm: https://doi.org/10.1023/A:1008306431147
- Scipy DIRECT docs: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.direct.html
- Parallel optimization discussion: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.differential_evolution.html#parallel-differential-evolution
